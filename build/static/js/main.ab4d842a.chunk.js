(this.webpackJsonpipp=this.webpackJsonpipp||[]).push([[0],{17:function(e){e.exports=JSON.parse('[{"label":"BraTS\'17: Data Request","description":"<P>Please fill in the following details to request the data from BraTS 2017 challenge. (https://www.med.upenn.edu/sbia/brats2017.html).\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"firstName":{"type":"string","label":"First Name","required":true},"lastName":{"type":"string","label":"Last Name","required":true},"experimentName":{"type":"string","label":"Single Word Team Name (this will show up in the leaderboard)","help":"A single word teamname is required.","required":true},"institutionalEmail":{"type":"string","label":"Institutional Email","help":"Irrespective to the email used for your ipp account, you need to use an institutional email address here.","required":true},"affiliation":{"type":"string","label":"Affiliation(s)/Institution(s)","help":"Please write all institutions and departments involved in your team.","required":true},"role":{"type":"string","label":"Role","help":"e.g.: Undergraduate, Postgraduate, PhD student, Postdoc, Assistant Professor.","required":true},"city":{"type":"string","label":"City","required":true},"country":{"type":"string","label":"Country","required":true}}}},"appKey":"BraTS17_data_request_registration"},{"label":"BraTS\'17 Testing Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data","help":"Use this section to upload your actual segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, you were given files called ID_t1.nii.gz, ID_t2.nii.gz, etc. Please upload segmentations called ID.nii.gz","required":true}}}},"appKey":"BraTS17eval_testingPhase"},{"label":"BraTS\'17 Testing Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your survival predictions and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Testing Data","help":"Use this section to upload a .CSV of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS17eval_testingPhase_Survival"},{"label":"BraTS\'17 Training Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data","help":"Use this section to upload your actual segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, you were given files called ID_t1.nii.gz, ID_t2.nii.gz, etc. Please upload segmentations called ID.nii.gz","required":true}}}},"appKey":"BraTS17eval_trainingPhase"},{"label":"BraTS\'17 Training Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your survival predictions and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Training Data","help":"Use this section to upload a .CSV of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS17eval_trainingPhase_Survival"},{"label":"BraTS\'17 Validation Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data","help":"Use this section to upload your actual segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, you were given files called ID_t1.nii.gz, ID_t2.nii.gz, etc. Please upload segmentations called ID.nii.gz","required":true}}}},"appKey":"BraTS17eval_validationPhase"},{"label":"BraTS\'17 Validation Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your survival predictions and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Validation Data","help":"Use this section to upload a .CSV of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS17eval_validationPhase_Survival"},{"label":"BraTS\'18: Data Request","description":"<P>Please fill out the following details to request a link to the BraTS 2018 training and validation data. You will receive a notification when the request is processed. Detailed instructions can be found at https://www.med.upenn.edu/sbia/brats2018.html. Note: If you have previously requested the data and need the link again, please simply fill out the form again and you will receive the same information.\\n<P>Note: If you have previously requested the data and need the link again, please simply fill out the form again and you will receive the same information.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"firstName":{"type":"string","label":"First Name","required":true},"lastName":{"type":"string","label":"Last Name","required":true},"experimentName":{"type":"string","label":"Team Name (this will show up in the leaderboard)","help":"A single word teamname is required.","required":true},"institutionalEmail":{"type":"string","label":"Institutional Email","help":"Irrespective to the email used for your ipp account, you need to use a preferably institutional email address here.","required":true},"affiliation":{"type":"string","label":"Affiliation(s)/Institution(s)","help":"Please write all institutions and departments involved in your team.","required":true},"role":{"type":"string","label":"Role","help":"e.g.: Undergraduate, Postgraduate, PhD student, Postdoc, Assistant Professor.","required":true},"city":{"type":"string","label":"City","required":true},"country":{"type":"string","label":"Country","required":true}}}},"appKey":"BraTS18_registration"},{"label":"BraTS\'18 Testing Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS2018 website (https://www.med.upenn.edu/sbia/brats2018.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your actual segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, you were given files called ID_t1.nii.gz, ID_t2.nii.gz, etc. Please upload segmentations called ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS18eval_testingPhase"},{"label":"BraTS\'18 Testing Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your survival predictions and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2018 website (https://www.med.upenn.edu/sbia/brats2018.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Testing Data","help":"Use this section to upload a .CSV of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS18eval_testingPhase_Survival"},{"label":"BraTS\'18 Training Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2018 website (https://www.med.upenn.edu/sbia/brats2018.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your actual segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, you were given files called ID_t1.nii.gz, ID_t2.nii.gz, etc. Please upload segmentations called ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS18eval_trainingPhase"},{"label":"BraTS\'18 Training Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your survival predictions and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2018 website (https://www.med.upenn.edu/sbia/brats2018.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Training Data","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS18eval_trainingPhase_Survival"},{"label":"BraTS\'18 Validation Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS2018 website (https://www.med.upenn.edu/sbia/brats2018.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your actual segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, you were given files called ID_t1.nii.gz, ID_t2.nii.gz, etc. Please upload segmentations called ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS18eval_validationPhase"},{"label":"BraTS\'18 Validation Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your survival predictions and be included in the leaderboard display you <b>must</b> be registered for the challenge via the BraTS 2018 website (https://www.med.upenn.edu/sbia/brats2018.html) using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Validation Data","help":"Use this section to upload a .CSV of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS18eval_validationPhase_Survival"},{"label":"BraTS\'19: Data Request","description":"<P>Please fill out the following details to request a link to the BraTS 2019 training and validation data. You will receive a notification when the request is processed. Detailed instructions can be found at https://www.med.upenn.edu/cbica/brats2019.html. Note: If you have previously requested the data and need the link again, please simply fill out the form again and you will receive the same information.\\n<P>Note: If you have previously requested the data and need the link again, please simply fill out the form again and you will receive the same information.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"firstName":{"type":"string","label":"First Name","required":true},"lastName":{"type":"string","label":"Last Name","required":true},"experimentName":{"type":"string","label":"Team Name (Single word without spaces; This is the name that will show up in the leaderboards)","help":"A single word teamname is required.","required":true},"institutionalEmail":{"type":"string","label":"Institutional Email","help":"Irrespective to the email used for your ipp account, you need to use a preferably institutional email address here.","required":true},"affiliation":{"type":"string","label":"Affiliation(s)/Institution(s)","help":"Please write all institutions and departments involved in your team.","required":true},"role":{"type":"string","label":"Role","help":"e.g.: Undergraduate, PhD student, Postdoc, Assistant Professor.","required":true},"city":{"type":"string","label":"City","required":true},"country":{"type":"string","label":"Country","required":true}}}},"appKey":"BraTS19_registration"},{"label":"BraTS\'19 Testing Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS19eval_testingPhase"},{"label":"BraTS\'19 Testing Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS19eval_testingPhase_Survival"},{"label":"BraTS\'19 Testing Data: Uncertainty Task","description":"<P>Please note that in order to be able to evaluate, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. There should be 4 segmentation maps uploaded per patient ID, having file names ID.nii.gz, ID_unc_whole.nii.gz, ID_unc_core.nii.gz, ID_unc_enhance.nii.gz, respectively.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS19eval_testingPhase_Uncertainty"},{"label":"BraTS\'19 Training Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS19eval_trainingPhase"},{"label":"BraTS\'19 Training Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS19eval_trainingPhase_Survival"},{"label":"BraTS\'19 Training Data: Uncertainty Task","description":"<P>Please note that in order to be able to evaluate, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. There should be 4 segmentation maps uploaded per patient ID, having file names ID.nii.gz, ID_unc_whole.nii.gz, ID_unc_core.nii.gz, ID_unc_enhance.nii.gz, respectively.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS19eval_trainingPhase_Uncertainty"},{"label":"BraTS\'19 Validation Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS19eval_validationPhase"},{"label":"BraTS\'19 Validation Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS19eval_validationPhase_Survival"},{"label":"BraTS\'19 Validation Data: Uncertainty Task","description":"<P>Please note that in order to be able to evaluate, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'19 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. There should be 4 segmentation maps uploaded per patient ID, having file names ID.nii.gz, ID_unc_whole.nii.gz, ID_unc_core.nii.gz, ID_unc_enhance.nii.gz, respectively.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS19eval_validationPhase_Uncertainty"},{"label":"BraTS\'20: Data Request","description":"<P>Please fill out the following details to request a link to the training data, as well as register your team for the BraTS 2020 challenge. You will receive a notification when the request is processed. Detailed instructions can be found at https://www.med.upenn.edu/cbica/brats2020.html. Note: If you have previously requested the data and need the link again, please simply fill out the form again and you will receive the same information.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"firstName":{"type":"string","label":"First Name","required":true},"lastName":{"type":"string","label":"Last Name","required":true},"experimentName":{"type":"string","label":"Team Name (Single word without spaces; This is the name that will show up in the leaderboards)","help":"A single word teamname is required.","required":true},"institutionalEmail":{"type":"string","label":"Institutional Email","help":"Irrespective to the email used for your ipp account, you need to use a preferably institutional email address here.","required":true},"affiliation":{"type":"string","label":"Affiliation(s)/Institution(s)","help":"Please write all institutions and departments involved in your team.","required":true},"role":{"type":"string","label":"Role","help":"e.g.: Undergraduate, PhD student, Postdoc, Assistant Professor.","required":true},"city":{"type":"string","label":"City","required":true},"country":{"type":"string","label":"Country","required":true}}}},"appKey":"BraTS20_registration"},{"label":"BraTS\'20 Testing Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz. Make sure to match the origin of your segmentations to the provided data.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS20eval_testingPhase"},{"label":"BraTS\'20 Testing Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS20eval_testingPhase_Survival"},{"label":"BraTS\'20 Testing Data: Uncertainty Task","description":"<P>Please note that in order to be able to evaluate, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. There should be 4 segmentation maps uploaded per patient ID, having file names ID.nii.gz, ID_unc_whole.nii.gz, ID_unc_core.nii.gz, ID_unc_enhance.nii.gz, respectively.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS20eval_testingPhase_Uncertainty"},{"label":"BraTS\'20 Training Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS20eval_trainingPhase"},{"label":"BraTS\'20 Training Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS20eval_trainingPhase_Survival"},{"label":"BraTS\'20 Training Data: Uncertainty Task","description":"<P>Please note that in order to be able to evaluate, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. There should be 4 segmentation maps uploaded per patient ID, having file names ID.nii.gz, ID_unc_whole.nii.gz, ID_unc_core.nii.gz, ID_unc_enhance.nii.gz, respectively.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS20eval_trainingPhase_Uncertainty"},{"label":"BraTS\'20 Validation Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS20eval_validationPhase"},{"label":"BraTS\'20 Validation Data: Survival Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your predicted survival values. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"inputSheet":{"type":"attachment","label":"Predicted Survival Values of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload a .csv of predicted survival values. The csv should NOT contain ANY HEADER, but only the subject IDs in the first column, and the survival in days in the second.","required":true}}}},"appKey":"BraTS20eval_validationPhase_Survival"},{"label":"BraTS\'20 Validation Data: Uncertainty Task","description":"<P>Please note that in order to be able to evaluate, you <b>must</b> be first registered for the challenge through the \\\\\\"BraTS\'20 Data Request\\\\\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"BraTS experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the BraTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. There should be 4 segmentation maps uploaded per patient ID, having file names ID.nii.gz, ID_unc_whole.nii.gz, ID_unc_core.nii.gz, ID_unc_enhance.nii.gz, respectively.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"}}}},"appKey":"BraTS20eval_validationPhase_Uncertainty"},{"label":"MICCAI BraTS 2017 Training Phase: All evaluation applications will be available shortly.","description":"<P><BR>\\nWe appreciate your interest in the International Multimodal Brain Tumor Segmentation Challenge 2017.\\n<BR>\\nPlease note that we are currently optimizing all the evaluation applications and the leaderboard display. Once everything is ready all participants registered for the challenge via the BraTS 2017 website (https://www.med.upenn.edu/sbia/brats2017.html) will receive email notifications.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Here you will be entering your team\'s name.","required":true},"subjectList":{"type":"attachment","label":"List of subjects","help":"Here you will be uploading a spreadsheet (.csv) of subjects that you want to evaluate their segmentations.","required":true},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels","help":"Here you will be uploading the actual segmentation labels in .nii.gz format.","required":true}}}},"appKey":"BraTS_2017"},{"label":"CaPTk Bias Correction","description":"<P><BR>\\nThis job runs bias correction algorithms on an image using CaPTk tools.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Primary Options","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"input":{"type":"attachment","label":"Input Image","help":"Input image in .nii.gz format (NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1},"mask":{"type":"attachment","label":"Image Mask","help":"Mask for the input image in .nii.gz format (NIfTI)","required":false,"validator":"/bin/true","min":1,"max":1},"correctionType":{"type":"select","label":"Indicate which bias correction algorithm to use","choices":{"-n3":"Use N3 bias correction algorithm","-n4":"Use N4 bias correction algorithm"},"required":true}}},"optional":{"label":"Additional Options","open":false,"fields":{"splineOrder":{"type":"integer","label":"The spline order for bias correction (defaults to 3)","def":3,"required":false},"filterNoise":{"type":"float","label":"The filter noise level for bias correction (defaults to 0.010000)","def":0.01,"required":false},"biasBins":{"type":"integer","label":"If no mask is specified, the number of histogram bins for Otsu used for mask generation (defaults to 3)","def":3,"required":false},"fittingLevels":{"type":"integer","label":"The number of fitting levels to use for bias correction (defaults to 4)","def":4,"required":false},"maxIterations":{"type":"integer","label":"Maximum number of iterations for bias correction (defaults to 100)","def":100,"required":false},"fwhm":{"type":"float","label":"The filter noise level for bias correction (defaults to 0.150000)","def":0.15,"required":false}}}},"appKey":"CaPTkBiasCorrection"},{"label":"CaPTk BraTS Preprocessing Pipeline","description":"<P><BR>\\nThis job runs the full BraTS preprocessing pipeline using CaPTk tools.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"t1ceImage":{"type":"attachment","label":"T1CE Image","help":"Input structural T1-weighted post-contrast image (DICOM or NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1},"t1Image":{"type":"attachment","label":"T1 Image","help":"Input structural T1-weighted pre-contrast image (DICOM or NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1},"t2Image":{"type":"attachment","label":"T2 Image","help":"Input structural T2-weighted contrast image (DICOM or NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1},"flImage":{"type":"attachment","label":"FLAIR Image","help":"Input structural FLAIR contrast image (DICOM or NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"skullStrip":{"type":"select","label":"Indicate whether to strip skulls from input (defaults to True)","choices":{"0":"do not perform skull stripping","1":"perform skull stripping"},"def":1,"required":false},"brainTumor":{"type":"select","label":"Indicate whether to segment brain tumors (defaults to True)","choices":{"0":"do not segment brain tumors","1":"segment brain tumors"},"def":1,"required":false}}}},"appKey":"CaPTkBraTSPreprocessingPipeline"},{"label":"CaPTk Diffusion Derivatives","description":"<P><BR>\\nThis job calculates diffusion derivatives of the input DWI image using the CaPTk DiffusionDerivatives tool.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"input":{"type":"attachment","label":"Input DWI File","help":"This is the NIfTI (.nii.gz) image from which diffusion derivatives will be calculated. ","required":true,"validator":"/bin/true","min":1,"max":1},"mask":{"type":"attachment","label":"Mask File","help":"Mask file in NIfTI format (.nii.gz) outlining the region of interest.","required":true,"validator":"/bin/true","min":1,"max":1},"Bval":{"type":"attachment","label":"Bval File","help":"This bval file is needed to calculate diffusion derivatives.","required":true,"validator":"/bin/true","min":1,"max":1},"Bvec":{"type":"attachment","label":"Bvec file","help":"This bvec file is needed to calculate diffusion derivatives.","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"axial":{"type":"select","label":"Indicate whether to generate the axial diffusivity image (defaults to True)","choices":{"0":"do not generate the axial diffusivity image","1":"generate the axial diffusivity image"},"def":1,"required":false},"fractional":{"type":"select","label":"Indicate whether to generate the fractional anisotropy image (defaults to True)","choices":{"0":"do not generate the fractional anisotropy image","1":"generate the fractional anisotropy image"},"def":1,"required":false},"radial":{"type":"select","label":"Indicate whether to generate the radial diffusivity image (defaults to True)","choices":{"0":"do not generate the radial diffusivity image","1":"generate the radial diffusivity image"},"def":1,"required":false},"coefficient":{"type":"select","label":"Indicate whether to generate apparent diffusion coefficient image (defaults to True)","choices":{"0":"do not generate the apparent diffusion coefficient image","1":"generate the apparent diffusion coefficient image"},"def":1,"required":false}}}},"appKey":"CaPTkDiffusionDerivatives"},{"label":"CaPTk Histogram Matching","description":"<P><BR>\\nThis job runs the Histogram Matching preprocessing algorithm on an image using CaPTk tools.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Primary Options","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"input":{"type":"attachment","label":"Input Image","help":"Input image in .nii.gz format (NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1},"matchImage":{"type":"attachment","label":"Image to Match","help":"Image to match to, in .nii.gz format (NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"matchBins":{"type":"integer","label":"Number of histogram bins for histogram matching (defaults to 100)","def":100,"required":false},"matchQnts":{"type":"integer","label":"Number of quantile values to match for histogram matching (defaults to 40)","def":40,"required":false}}}},"appKey":"CaPTkHistogramMatching"},{"label":"CaPTk Image Registration","description":"<P><BR>\\nThis job registers moving images with a fixed image using CaPTk preprocessing tools.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"inputImage":{"type":"attachment","label":"Moving Image","help":"Input moving image file (.nii.gz)","required":true,"validator":"/bin/true","min":1,"max":1},"regFixedImg":{"type":"attachment","label":"Fixed Image","help":"Fixed image file (.nii.gz)","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"maskImage":{"type":"attachment","label":"Mask Image","help":"Mask file (.nii.gz) indicating region to register","required":false,"validator":"/bin/true","min":1,"max":1},"registration":{"type":"string","label":"Registration Type","help":"Valid values: Affine, Deformable, Rigid. You can also specify Affine-DOF where DOF is the number of degrees of freedom, e.g. Affine-12 for 12 degrees of freedom. Defaults to Affine.","def":"Affine","required":false},"regMetrics":{"type":"string","label":"Registration Metrics","help":"Valid values: SSD (Sum of Squared Differences), MI (Mutual Information), NMI (Normalized Mutual Information), or NCC-AxBxC (Normalized cross correlation where A, B and C are integer radii). Defaults to NMI.","def":"NMI","required":false},"regNoIters":{"type":"string","label":"Number of iterations per multi-res level","help":"Format: N1,N2,N3 where N1, N2 and N3 are integers. Default: 100,50,5","def":"100,50,5","required":false},"regSegMoving":{"type":"select","label":"Indicate if moving image is a segmentation file","help":"True if the moving image is a segmentation file, false otherwise. If true, nearest-label interpolation is applied. Default: false","choices":{"0":"moving image is an image file","1":"moving image is a segmentation file"},"def":0,"required":false}}}},"appKey":"CaPTkImageRegistration"},{"label":"CaPTk Perfusion Derivatives","description":"<P><BR>\\nThis job calculates perfusion derivatives of the input image using the CaPTk PerfusionDerivatives tool.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"input":{"type":"attachment","label":"Input DSC-MRI Image","help":"Input DSC-MRI image in NIfTI format (.nii.gz) from which to extract perfusion derivatives.","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"PSR":{"type":"select","label":"Indicate whether to generate the Percent Signal Recovery (PSR) image (defaults to True)","choices":{"0":"do not generate the PSR image","1":"generate the PSR image"},"def":1,"required":false},"peakHeight":{"type":"select","label":"Indicate whether to generate the Peak Height image (defaults to True)","choices":{"0":"do not generate the peak height image","1":"generate the peak height image"},"def":1,"required":false},"apRCBV":{"type":"select","label":"Indicate whether to extract the automatically-extraction proxy to relative cerebral volume (apRCBV) image (defaults to True)","choices":{"0":"do not generate the apRCBV image","1":"generate the apRCBV image"},"def":1,"required":false}}}},"appKey":"CaPTkPerfusionDerivatives"},{"label":"CaPTk SUSAN Denoising","description":"<P><BR>\\nThis job runs the SUSAN denoising algorithm on an image using CaPTk tools.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Primary Options","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"input":{"type":"attachment","label":"Input Image","help":"Input image in .nii.gz format (NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"susanSigma":{"type":"float","label":"Susan smoothing Sigma value (defaults to 0.50000)","def":0.5,"required":false},"susanRadius":{"type":"float","label":"Susan smoothing Radius value (defaults to 0.010000)","def":0.01,"required":false},"susanThresh":{"type":"float","label":"Susan smoothing Intensity Variation Threshold value (defaults to 80.00000)","def":80,"required":false}}}},"appKey":"CaPTkSusanDenoising"},{"label":"CaPTk Z-Score Normalization","description":"<P><BR>\\nThis job runs the Z-Score Normalization algorithm on an image using CaPTk tools.\\n<BR><BR><BR>\\n $Revision$\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Primary Options","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"input":{"type":"attachment","label":"Input Image","help":"Input image in .nii.gz format (NIfTI)","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"normQuant":{"type":"string","label":"The Lower-Upper quantile range to remove (ex. 5,95)","def":"5,95","required":false},"normCut":{"type":"string","label":"The Lower-Upper Cut-off (multiple of standard deviation) to remove (ex. 3,3)","def":"3,3","required":false}}}},"appKey":"CaPTkZScoreNormalization"},{"label":"COMPARE: Classification Of Morphological Patterns using Adaptive Regional Elements","description":"<B><A HREF=\\"https://www.cbica.upenn.edu/sbia/projects/COMPARE.html\\">COMPARE Web page</A></B>\\n<P><BR>\\nThis software requires two groups of images (feature maps), one for patients and the other for controls.<br>\\n<B> The main output is a text file with classification results.</B>\\n","fieldGroups":{"required":{"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"group1files":{"help":"List of image files of group1 (will be labelled as +1)","label":"List of Image Files of Group1","max":1000,"min":2,"required":true,"type":"attachment"},"group2files":{"help":"List of image files of group2 (will be labelled as -1)","label":"List of Image Files of Group2","max":1000,"min":2,"required":true,"type":"attachment"},"outputPrefix":{"help":"Prefix of the output filename","label":"Output file","required":true,"type":"string"}},"label":"Required Fields","open":true},"optional":{"fields":{"k":{"def":1,"help":"std value for Gaussian kernel in SVM (range:1~10000. This value is multiplied by 100! default:1)","label":"kernelwidth","required":false,"type":"integer","max":100,"min":1},"j":{"def":2,"help":"searching range for std value (should be greater than above value, optional)","label":"kernelwidthbig","required":false,"type":"integer","max":100,"min":2},"c":{"def":10,"help":"trade-off value in SVM (range:1~10000, default: 10)","label":"ctradeoff","required":false,"type":"integer","max":100,"min":1},"s":{"def":3,"help":" Gaussian kernel size for smoothing score map (default: 3.0, range:1~10)","label":"skernelwidth","required":false,"type":"float","max":10,"min":0.1},"n":{"def":150,"help":" searching space of feature number (range:1~1500, default: 150)","label":"nsearchingspace","required":false,"type":"integer","max":1000,"min":20},"testingsfiles":{"help":"List of image files of testing group","label":"testingfiles","required":false,"type":"attachment"}},"label":"Options","open":true}},"starter":"/bin/true","validator":"/bin/true","appKey":"Compare"},{"label":"DeepBrainNet Age Prediction","description":"Pipeline to obtain age prediction from T1 MRI scan","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Experiment Description (optional)"},"subjectImage1":{"type":"attachment","label":"Subject Nifti image (..._T1.nii.gz)","help":"Subject image in Nifti format (named ..._T1.nii.gz)","required":true,"min":1,"max":1}}}},"appKey":"DBN_def"},{"label":"DRAMMS RAVENS Analysis","description":"<B><A HREF=\\"http://www.cbica.upenn.edu/sbia/software/dramms/tools/ravens.html\\">DRAMMS RAVENS Web page</A></B>\\n<P><BR>\\nDRAMMS - Deformable Registration via Attribute Matching and Mutual-Saliency Weighting<BR>\\n\\nThis is suitable if you have no deformation yet. This requires only two input images, and the label map in the source image space. From these, users may want to calculate the RAVENS maps in one step.<br>\\n<B>Please note:</B> the registered image is in the source space and the RAVENS maps are in the target space.\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"subjectImage1":{"type":"attachment","label":"Subject Image 1","help":"Subject image, type NIFTi or ANALYZE","required":true,"validator":"/home/nodeapps/bin/validateimage --imagefile %filename%","min":1,"max":1},"subjectImage2":{"type":"attachment","label":"Segmented Image","help":"Segmented image, type NIFTi or ANALYZE","required":true,"validator":"/home/nodeapps/bin/validateimage --imagefile %filename%","min":1},"templateImage":{"type":"attachment","label":"Template Image","help":"Template image, type NIFTi or ANALYZE","required":true,"validator":"/home/nodeapps/bin/validateimage --imagefile %filename%","min":1,"max":1},"outputImageName":{"type":"string","label":"Prefix of RAVENS filenames","help":"","required":true,"min":4,"max":48},"labelRegions":{"type":"string","label":"Regions to label","required":true,"def":"10,150,250","help":"This argument specifies the labels of the regions (defined in the supplied Segmented Image file) in which RAVENS maps will be calculated. For example, \'10,150,150\' results in the computation of three RAVENS maps, one for each region labeled by 10, 150, 250 in the supplied segmented image. Up to 5 labels can be specified at a time."}}}},"appKey":"DRAMMS-Ravens"},{"label":"DeepLearningSegmentation_BrainTumor","description":"<P>Deep Learning based Brain Tumor Segmentation from CaPTk. Coming Soon.\\n\\nVersion 1.7.2\\nCopyright (c) 2019 University of Pennsylvania. All rights reserved.\\nSee http://www.cbica.upenn.edu/sbia/software/license.html\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Experiment Description (optional)","help":"We strongly suggest use of this space to make it recognizable for you. This will be incredibly useful if you intend to make multiple submissions."},"t1cImage":{"type":"attachment","label":"T1CE/T1Gd Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume; should be skull-stripped\\nT2 image - describes the subject\'s native T2-weighted MRI volume; should be skull-stripped\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume; should be skull-stripped\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume; should be skull-stripped\\n","required":true,"validator":"/bin/true","min":1,"max":1},"t1Image":{"type":"attachment","label":"T1 Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume; should be skull-stripped\\nT2 image - describes the subject\'s native T2-weighted MRI volume; should be skull-stripped\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume; should be skull-stripped\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume; should be skull-stripped\\n","required":true,"validator":"/bin/true","min":1,"max":1},"t2Image":{"type":"attachment","label":"T2 Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume; should be skull-stripped\\nT2 image - describes the subject\'s native T2-weighted MRI volume; should be skull-stripped\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume; should be skull-stripped\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume; should be skull-stripped\\n","required":true,"validator":"/bin/true","min":1,"max":1},"flImage":{"type":"attachment","label":"FL Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume; should be skull-stripped\\nT2 image - describes the subject\'s native T2-weighted MRI volume; should be skull-stripped\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume; should be skull-stripped\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume; should be skull-stripped\\n","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Options","open":false,"fields":{"maskFile":{"help":"This is the brain mask file used for normalization. Should be in the same space as the other input images.\\n","type":"attachment","label":"Mask Image (.nii.gz)"}}}},"appKey":"DeepMedic_brainTumor"},{"label":"Deep Learning - Modality Agnostic Skull Stripping","description":"<P>Deep Learning based modality-agnostic Skull Stripping/Segmentation from CaPTk.\\n\\nVersion 1.8.1\\nCopyright (c) 2020 University of Pennsylvania. All rights reserved.\\nSee http://www.cbica.upenn.edu/sbia/software/license.html\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Experiment Description (optional)","help":"We strongly suggest use of this space to make it recognizable for you. This will be incredibly useful if you intend to make multiple submissions."},"inputImage":{"type":"attachment","label":"Input Image (.nii.gz)","help":"This skull-stripping model is modality-agnostic and requires just one structural MRI image.\\n","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Options","open":false,"fields":{"maskFile":{"help":"This is the brain mask file used for normalization. Should be in the same space as the input image.\\n","type":"attachment","label":"Mask Image (.nii.gz)"}}}},"appKey":"DeepMedic_modalityagnostic_skullstripping"},{"label":"DeepLearningSegmentation_Skull","description":"<P>Deep Learning based Skull Stripping/Segmentation from CaPTk. Coming Soon.\\n\\nVersion 1.7.2\\nCopyright (c) 2019 University of Pennsylvania. All rights reserved.\\nSee http://www.cbica.upenn.edu/sbia/software/license.html\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Experiment Description (optional)","help":"We strongly suggest use of this space to make it recognizable for you. This will be incredibly useful if you intend to make multiple submissions."},"t1cImage":{"type":"attachment","label":"T1CE/T1Gd Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume\\nT2 image - describes the subject\'s native T2-weighted MRI volume\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume\\n","required":true,"validator":"/bin/true","min":1,"max":1},"t1Image":{"type":"attachment","label":"T1 Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume\\nT2 image - describes the subject\'s native T2-weighted MRI volume\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume\\n","required":true,"validator":"/bin/true","min":1,"max":1},"t2Image":{"type":"attachment","label":"T2 Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume\\nT2 image - describes the subject\'s native T2-weighted MRI volume\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume\\n","required":true,"validator":"/bin/true","min":1,"max":1},"flImage":{"type":"attachment","label":"FL Image (.nii.gz)","help":"DL_Skull requires 4 images (all co-registered):\\nT1 image - describes the subject\'s native T1-weighted MRI volume\\nT2 image - describes the subject\'s native T2-weighted MRI volume\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume\\n","required":true,"validator":"/bin/true","min":1,"max":1}}},"optional":{"label":"Options","open":false,"fields":{"maskFile":{"help":"This is the brain mask file used for normalization. Should be in the same space as the other input images.\\n","type":"attachment","label":"Mask Image (.nii.gz)"}}}},"appKey":"DeepMedic_skullStripping"},{"label":"FeTS\'21: Registration and Data Request","description":"<P>Please fill out the following details to register for the FeTS 2021 challenge. You will receive a notification when the request is processed. \\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"firstName":{"type":"string","label":"First Name","required":true},"lastName":{"type":"string","label":"Last Name","required":true},"experimentName":{"type":"string","label":"Team Name (Single word. This is the name that will appear in the leaderboards)","help":"A single word teamname is required, and any spaces will be automatically replaced with an underscore. Please try to pick a name that is unique to your team as you will not be able to register if the teamname overlaps with another existing registration.","required":true},"institutionalEmail":{"type":"string","label":"Institutional Email","help":"Irrespective to the email used for your ipp account, an institutional (either academic, or industrial) email address is required for registration.","required":true},"affiliation":{"type":"string","label":"Main Affiliation","help":"Please enter the institution of your main affiliation for your team.","required":true},"researchGroup":{"type":"string","label":"Research Group/Lab Name","help":"Please enter the name of your Research Group/Lab.","required":true},"role":{"type":"string","label":"Role","help":"e.g.: Undergraduate, PhD student, Postdoc, Assistant Professor.","required":true},"city":{"type":"string","label":"City","required":true},"country":{"type":"string","label":"Country","required":true},"PIfirstName":{"type":"string","label":"PI First Name","required":false},"PIlastName":{"type":"string","label":"PI Last Name","required":false},"PIemail":{"type":"string","label":"PI email address","required":false},"declaration":{"type":"select","label":"By clicking the Submit button below, I declare that I do not intend to perform any malicious activities on machines where my submitted application is executed.","choices":{"1":"I accept"},"required":true}}}},"appKey":"FeTS21_registration"},{"label":"FeTS\'21 Testing Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels and be included in the leaderboard display, you <b>must</b> be first registere for the challenge through the \\"FeTS\'21 Registration and Data Request\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Testing Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the FeTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz. Make sure to match the origin of your segmentations to the provided data.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"},"declaration":{"type":"select","label":"By participating and submitting results to the FeTS 2021 challenge for evaluation during the testing/ranking phase, I confirm that my code follows a license conforming to one of the standards: Apache 2.0, BSD-style, or MIT.","choices":{"1":"I accept"},"required":true}}}},"appKey":"FeTS21eval_testingPhase"},{"label":"FeTS\'21 Training Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels, you <b>must</b> be first registere for the challenge through the \\"FeTS\'21 Registration and Data Request\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Training Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the FeTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"},"declaration":{"type":"select","label":"By clicking the Submit Job button below, I declare that I do not intend to perform any malicious activities on machines where my submitted application is executed.","choices":{"1":"I accept"},"required":true}}}},"appKey":"FeTS21eval_trainingPhase"},{"label":"FeTS\'21 Validation Data: Segmentation Task","description":"<P>Please note that in order to be able to evaluate your segmentation labels, you <b>must</b> be first registere for the challenge through the \\"FeTS\'21 Registration and Data Request\\" application in the CBICA Image Processing Portal using <b>the same email address</b> as the one you used to register in this portal.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to define the method/parameters you used to produce your segmentation labels. This will be incredibly useful if you intend to make multiple submissions and optimize your method accordingly.","required":true,"def":"experiment description goes here"},"segmentationLabels":{"type":"attachment","label":"Segmentation Labels of Validation Data (Note: These uploaded files are kept by the IPP for future reference and evaluation within the scope of the FeTS challenge.)","help":"Use this section to upload your segmentation labels in .nii.gz format. Note that each file should be named using the patient ID, given by the folder name containing the 4 modalities for each patient. In other words, for subjects that you were given files named ID_t1.nii.gz, ID_t2.nii.gz, etc., the uploaded segmenations should be named ID.nii.gz","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%"},"declaration":{"type":"select","label":"By clicking the Submit Job button below, I declare that I do not intend to perform any malicious activities on machines where my submitted application is executed.","choices":{"1":"I accept"},"required":true}}}},"appKey":"FeTS21eval_validationPhase"},{"label":"FeatureExtraction","description":"<P>Feature Extraction from CaPTk. Coming Soon.\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment description.","help":"We strongly suggest use of this space to make it recognizable for you. This will be incredibly useful if you intend to make multiple submissions.","required":true,"def":"Your submission name goes here."}}}},"appKey":"FeatureExtraction"},{"label":"GLISTR","description":"<P><BR>\\nGLISTR: Glioma Image Segmentation and Registration\\nVersion 3.1.0\\nCopyright (c) 2014 University of Pennsylvania. All rights reserved.\\nSee http://www.cbica.upenn.edu/sbia/software/license.html\\nDEPRECATED\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Experiment Description (optional)","help":"We strongly suggest use of this space to make it recognizable for you. This will be incredibly useful if you intend to make multiple submissions."},"images":{"type":"attachment","label":"Required images (.nii.gz)","help":"GLISTR requires 4 images:\\nT1 image - describes the subject\'s native T1-weighted MRI volume\\nT2 image - describes the subject\'s native T2-weighted MRI volume\\nT1CE image - describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume\\nFLAIR image - describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume\\n","required":true,"validator":"/bin/true","min":4,"max":4},"seedFile":{"type":"attachment","label":"Tumor seedpoint file","help":"This is a .txt file that specifies tumor location and radius to roughly approximate its volume. We have developed \'BrainTumorViewer\' (https://www.cbica.upenn.edu/sbia/software/braintumorviewer/) specifically for creating this file. However, you can use any software you want in order to create it as long as it is saved in the very same structure. More information on the exact structure of the file can be found in the pages of GLISTR (https://www.cbica.upenn.edu/sbia/software/glistr/manual.html).","required":true,"min":1,"max":1},"pointFile":{"type":"attachment","label":"Tissue seedpoint file","help":"This is a .txt file that specifies coordinates (x,y,z) used to model the intensity distribution of each tissue type under segmentation. We have developed \'BrainTumorViewer\' (https://www.cbica.upenn.edu/sbia/software/braintumorviewer/) specifically for creating this file. However, you can use any software you want in order to create it as long as it is saved in the very same structure. More information on the exact structure of the file can be found in the pages of GLISTR (https://www.cbica.upenn.edu/sbia/software/glistr/manual.html).","required":true,"min":1,"max":1},"atlasFolder":{"type":"string","label":"Atlas Folder","help":"For example: atlas_jakob_with_cere_type","required":true}}},"optional":{"label":"Options","open":false,"fields":{"numOmpThreads":{"type":"integer","label":"Number of OpenMP threads","min":1,"max":3,"def":3},"numItkThreads":{"type":"integer","label":"Number of ITK threads","min":1,"max":3,"def":3},"numHopThreads":{"type":"integer","label":"Number of Hopspack threads","min":1,"max":3,"def":1}}}},"appKey":"GLISTR"},{"label":"GLISTRboost: Brain Tumor Segmentation (BRATS\'15 winning method)","description":"<P><BR>\\nThis application runs our method proposed for segmenting low- and high-grade gliomas in multimodal magnetic resonance imaging (MRI) volumes.\\n<BR>\\nNote that this is the winning method of the Multimodal Brain Tumor Image Segmentation (BRATS) Challenge, held in conjunction with the Medical Image Computing and Computer Assisted Intervention (MICCAI) conference in Technische Universitaet Muenchen (TUM) in Munich (Germany) - October 2015.\\n<BR>\\nThe proposed approach is based on a hybrid generative-discriminative model. Firstly, a generative approach of a joint segmentation-registration scheme based on an Expectation-Maximization framework, that incorporates a glioma growth model, is used to segment the brain scans into tumor and healthy tissue labels. Secondly, a discriminative, gradient boosting multi-class classification, scheme is used to refine tumor labels based on information from multiple patients. Lastly, a probabilistic Bayesian strategy is employed to further refine and finalize the tumor segmentation based on patient-specific intensity statistics from the multiple modalities.\\n<BR>\\n<BR>\\nAssumptions: All input MRI volumes (i.e. T1, T1-Gad, T2, T2-FLAIR) must be skull-stripped, resampled to 1mm^3, co-registered and in the LPS coordinate system, for the method to produce meaningful results.\\n<BR>\\n<BR>\\nReferences: Please cite the following publications when using data produced by the hereby application:\\n<BR>- Spyridon Bakas, Ke Zeng, Aristeidis Sotiras, Saima Rathore, Hamed Akbari, Bilwaj Gaonkar, Martin Rozycki, Sarthak Pati, Christos Davatzikos, \\"GLISTRboost: Combining Multimodal MRI Segmentation, Registration, and Biophysical Tumor Growth Modeling with Gradient Boosting Machines for Glioma Segmentation\\", Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, Springer, LNCS, 9556:144-155, 2016. DOI: 10.1007/978-3-319-30858-6_13\\n<BR>- Spyridon Bakas, Ke Zeng, Aristeidis Sotiras, Saima Rathore, Hamed Akbari, Bilwaj Gaonkar, Martin Rozycki, Sarthak Pati, Christos Davatzikos, \\"Segmentation of Gliomas in Multimodal Magnetic Resonance Imaging Volumes Based on a Hybrid Generative-Discriminative Framework\\", In Proceedings of the Multimodal Brain Tumor Image Segmentation Challenge held in conjunction with MICCAI 2015 (MICCAI-BRATS 2015), Technische Universit\xe4t M\xfcnchen (T.U.M.), Munich, Germany, 5-9 Oct 2015\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment (used for tracking its progress).","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"imageT1":{"type":"attachment","label":"T1 Image","help":"This describes the subject\'s native T1-weighted MRI volume. Note that this must be skull-stripped, co-registered with the other modalities and oriented Right-to-Left,Anterior-to-Posterior,Inferior-to-Superior.","required":true},"imageT2":{"type":"attachment","label":"T2 Image","help":"This describes the subject\'s native T2-weighted MRI volume. Note that this must be skull-stripped, co-registered with the other modalities and oriented Right-to-Left,Anterior-to-Posterior,Inferior-to-Superior.","required":true},"imageT1gad":{"type":"attachment","label":"T1-Gad Image","help":"This describes the subject\'s post-contrast (contrast-enhanced) T1-weighted MRI volume. Note that this must be skull-stripped, co-registered with the other modalities and oriented Right-to-Left,Anterior-to-Posterior,Inferior-to-Superior.","required":true},"imageFlair":{"type":"attachment","label":"T2-FLAIR Image","help":"This describes the subject\'s T2 Fluid-attenuated inversion recovery (FLAIR) MRI volume. Note that this must be skull-stripped, co-registered with the other modalities and oriented Right-to-Left,Anterior-to-Posterior,Inferior-to-Superior.","required":true},"seedFile":{"type":"attachment","label":"Tumor seedpoint file","help":"This is a .txt file that specifies tumor location and radius to roughly approximate its volume. We have developed \'BrainTumorViewer\' (https://www.cbica.upenn.edu/sbia/software/braintumorviewer/) specifically for creating this file. However, you can use any software you want in order to create it as long as it is saved in the very same structure. More information on the exact structure of the file can be found in the pages of GLISTR (https://www.cbica.upenn.edu/sbia/software/glistr/manual.html).","required":true},"pointFile":{"type":"attachment","label":"Tissue seedpoint file","help":"This is a .txt file that specifies coordinates (x,y,z) used to model the intensity distribution of each tissue type under segmentation. We have developed \'BrainTumorViewer\' (https://www.cbica.upenn.edu/sbia/software/braintumorviewer/) specifically for creating this file. However, you can use any software you want in order to create it as long as it is saved in the very same structure. More information on the exact structure of the file can be found in the pages of GLISTR (https://www.cbica.upenn.edu/sbia/software/glistr/manual.html).","required":true}}}},"appKey":"GLISTRboost"},{"label":"GraSP: Geodesic graph-based segmentation with shape priors","description":"<B><A HREF=\\"https://www.cbica.upenn.edu/sbia/software/grasp/index.html\\">GraSP web page</A></B>\\n<P><BR>\\nGraSP is a graph-based parcellation software. GraSP was initially developed for parcellating the cortex into functionally coherent regions, based on their Pearson correlation.\\n<P><BR>\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"mask":{"type":"attachment","label":"Mask","help":"This mask will be parcellated by GraSP. The expected file type is \'.nii.gz\'","required":true,"min":1,"max":1},"scans":{"type":"attachment","label":"Patient images to run GraSP on","help":"Patient fmri scans. The expected file type is a 4D \'.nii.gz\'","required":true,"min":1},"k":{"type":"float","label":"Penalty for introducing a novel parcel","help":"The higher the penalty, the smaller the number of parcels in the final parcellation.","required":true,"min":0.01,"max":1000,"def":10},"fr":{"type":"float","label":"Size of the largest expected parcel.","help":"This upper bound is used for speeding up the computation. This value is provided as a fraction of the whole brain.","required":true,"min":0.0005,"max":0.99,"def":0.05}}}},"appKey":"GraSP"},{"label":"LIBRA: Breast Density Estimation","description":"<B><A HREF=\\"http://www.cbica.upenn.edu/sbia/software/LIBRA/index.html\\">LIBRA Web page</A></B>\\n<P><BR>\\nLIBRA applies an edge-detection algorithm to delineate the boundary of the breast and the boundary of the pectoral muscle. Following the segmentation of the breast, an adaptive multi-class fuzzy c-means algorithm is applied to identify and partition the mammographic breast tissue area, into multiple regions (i.e., clusters) of similar x-ray attenuation. These clusters are then aggregated by a support-vector machine classifier to a final dense tissue area, segmentation. The ratio of the segmented absolute dense area to the total breast area is then used to obtain a measure of breast percent density (PD%).\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)"},"mammograms":{"type":"attachment","label":"Input digital mammogram(s)","help":"Digital mammogram(s), type DICOM","required":true,"validator":"/home/nodeapps/bin/validateimage --type dicom --imagefile %filename%","min":1,"max":100}}},"optional":{"label":"Options","open":false,"fields":{"saveIntermediateFiles":{"type":"select","label":"To save intermediate files","help":"Additional files for visualization, debugging and understanding the algorithm step-by-step.","choices":{"0":"NO","1":"YES"}}}}},"appKey":"LIBRA"},{"label":"MultiSiteSCZClassifier: Healthy-Control/Schizophrenia Binary Classification ","description":"<P><BR>\\nThis application applies a control/schizophrenia classifier trained on 835 subjects from several global sites on a new subject. \\n<BR>\\nAssumptions: The classifier only requires a skull-stripped t1-image for each subject.\\n<BR>\\n","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment (used for tracking its progress).","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"imageT1":{"type":"attachment","label":"T1 Image","help":"The subject\'s native T1-weighted MRI volume. Note that this must be skull-stripped and oriented Right-to-Left,Anterior-to-Posterior,Inferior-to-Superior.","required":true},"Age":{"type":"string","label":"Age of Subject","help":"Please input a value. Integer or float.","required":true},"Sex":{"type":"string","label":"Gender of Subject","help":"Please input a value. 0 for male. 1 for female.","required":true},"verbose":{"type":"select","label":"Verbose Output","open":false,"choices":{"0":"No","1":"Yes"},"def":1,"help":"Give verbose output"}}}},"appKey":"MultiSiteSCZClassifier"},{"label":"ODVBA: Optimally-Discriminative Voxel-Based Analysis","description":"<B><A HREF=\\"https://www.cbica.upenn.edu/sbia/software/odvba/index.html\\">ODVBA Web page</A></B>\\n<P><BR>\\nODVBA is used to determine the optimal spatially adaptive smoothing of images, followed by applying a voxel-based group analysis.<BR>\\n<B>The ouput is the p-map file.</B>\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"controlImages":{"type":"attachment","label":"Control images to run ODVBA on","help":"The images which are used as control. The expected file type is \'.nii.gz\'","required":true},"patientImages":{"type":"attachment","label":"Patient images to run ODVBA on","help":"The patient images. The expected file type is \'.nii.gz\'","required":true},"numNi":{"type":"integer","label":"Number of neighborhoods to consider","help":"At most, the neighborhood around each non-zero voxel can be considered. Use values between 5000-20000 (default is 10000).","required":true,"min":5000,"max":20000,"def":10000}}},"optional":{"label":"Options","open":true,"fields":{"sizeNi":{"type":"integer","label":"Size of neighborhood","help":"The neightborhood around each considered voxel. Use values between 9-17 (default is 15).","required":false,"min":9,"max":17,"def":15},"count":{"type":"integer","label":"Count of voxels in each neighborhood","help":"Use values between 200-500 (default is 400).","required":false,"min":200,"max":500,"def":400},"permsNum":{"type":"integer","label":"Number of permutations to test","required":false,"min":100,"max":10000,"def":200},"exponent":{"type":"float","label":"Exponent phi of discrimination degree","help":"Refer Eq.(11) of MICCAI paper for details. Use values between 0-10 (default is 1).","required":false,"min":0,"max":10,"def":1}}}},"appKey":"ODVBA"},{"label":"SCPLearn: Identification of Sparse Connectivity Patterns using rsfMRI","description":"<B><A HREF=\\"http://www.cbica.upenn.edu/sbia/software/SCPLearn/index.html\\">SCPLearn Web page</A></B>\\n<P><BR>\\nSCPLearn calculates Sparse Connectivity Patterns from rsfMRI Data.<br>\\nThis software requires a list of nifti files, a node definition/atlas nifti file. <br>\\nTwo main outputs are the SCPs in nifti format, and SCP coefficients saved in csv file.\\n","fieldGroups":{"required":{"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"atlasFile":{"help":"Nifti ROI/parcel/atlas file","label":"Nifti Atlas File","min":1,"required":true,"type":"attachment","validator":"/home/nodeapps/bin/validateimage --imagefile %filename%"},"data":{"help":"Resting state fMRI images of Nifti format to generate Sparse Connectivity Patterns from.(min: 1, max: 100)","label":"Data Files","min":1,"max":100,"required":true,"type":"attachment","validator":"/home/nodeapps/bin/validateimage --imagefile %filename%"}},"label":"Required Fields","open":true},"optional":{"fields":{"levels":{"help":"Select if you want hierarchical parcellation","label":"Hierarchy","required":false,"type":"select","choices":{"0":"No","1":"Yes"},"def":0},"numberOfSCPs":{"def":10,"help":"This value sets the number of SCPs. Default is 10.","label":"Number of SCPs","max":100,"min":1,"required":false,"type":"integer"},"pruning":{"def":1,"help":"The pruning threshold as a value between [0,1]. Default = 1","label":"Pruning threshold","max":1,"min":0,"required":false,"type":"float"}},"label":"Options","open":false}},"starter":"/bin/true","validator":"/bin/true","appKey":"SCPLearn"},{"label":"Structural Processing Pipeline","description":"<P><BR>\\nThis would run the structural processing pipeline for T1 images. It includes, \\n\\t<p> 1. Bias Correction ( N4 )\\n\\t<p> 2. Skull-Stripping ( MASS )\\n\\t<p> 3. ROI Segmentation ( MUSE )\\n\\t<p> 4. Tissue segmentation ( MICO )\\n\\t<p> 5. RAVENS maps ( DRAMMS )\\n<P>\\nYou may customize which ones to apply.\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"subjectImage1":{"type":"attachment","label":"Subject Image","help":"Type NIFTi. Providing multiple images will run the chosen pipeline for each image.","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%","min":1,"max":255}}},"optional":{"label":"Options","open":true,"fields":{"runN4":{"type":"select","required":false,"label":"Apply N4 Bias Correction","help":"Suffix: <b>_N4.nii.gz</b>.","choices":{"0":"NO","1":"YES"},"def":1},"runSS":{"type":"select","required":false,"label":"Apply Skull-Stripping","choices":{"0":"NO","1":"YES"},"def":1},"runMARS":{"type":"select","required":false,"label":"Apply MARS ROI labeling","help":"Suffix: <b>_labeled_SimRank+IC+FS.nii.gz</b> and <b>_Derived.csv</b>.","choices":{"0":"NO","1":"YES"},"def":1},"runSEG":{"type":"select","required":false,"label":"Run MICO Segmentation","help":"Suffix: <b>_mico.nii.gz</b>.","choices":{"0":"NO","1":"YES"},"def":1},"runRAVENS":{"type":"select","required":false,"label":"Run RAVENS deformations","help":"Outputs one RAVENS maps, normalized, downsampled, and smoothed for each tissue type.","choices":{"0":"NO","1":"YES"},"def":1}}}},"appKey":"StructuralPipeline"},{"label":"BrainMaGe Skull Stripping Pipeline","description":"<P><BR>\\nBrain Mask Generator (BrainMaGe) is a deep learning segmentation algorithm to generate robust and accurate brain masks given any single (or multiple) MR sequences. It has been developed while considering brain MRI scans with apparent abnormalities, such as diffuse gliomas, and its generalizability was evaluated on multi-institutional data of real clinical practice. We expect its novel \u201cmodality-agnostic\u201d strategy to contribute in its widespread application on brain MR scans inclusive of apparent tumors, lesions, white matter hyperintensities, as well as healthy brains.\\nReference:\\nS.Thakur, J.Doshi, S.Pati, S.Rathore, C.Sako, M.Bilello, et al., \u201cBrain extraction on MRI scans in presence of diffuse glioma: Multi-institutional performance evaluation of deep learning methods and robust modality-agnostic training, NeuroImage, 220:117081, 2020. DOI: 10.1016/j.neuroimage.2020.117081\\n<BR><BR><BR>\\n$Revision: 340 $\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)","required":false},"Images":{"type":"attachment","label":"Nifti Images","help":"Input structural images (NIfTI)","required":true,"validator":"/bin/true","min":1}}},"optional":{"label":"Additional Options","open":false,"fields":{"outputVolumes":{"type":"select","label":"Indicate whether to output segmented brain volumes in addition to masks (defaults to False)","choices":{"0":"do not output segmented brain volumes","1":"output segmented brain volumes"},"def":0,"required":false}}}},"appKey":"brainmage_v1"},{"label":"Multi Atlas Skull-Stripping (MASS)","description":"<B><A HREF=\\"https://www.cbica.upenn.edu/sbia/software/MASS/index.html\\">MASS Web page</A></B>\\n<P><BR>\\nMulti Atlas Skull Stripping (MASS), is a software package designed for robust and accurate brain extraction, \\napplicable for both individual as well as large population studies.\\n<P><BR>\\n\\n<B><A> Citation</A></B>: Jimit Doshi, Guray Erus, Yangming Ou, Bilwaj Gaonkar, Christos Davatzikos, Multi-Atlas Skull-Stripping, Academic Radiology, Volume 20, Issue 12, December 2013, Pages 1566-1576, ISSN 1076-6332, http://dx.doi.org/10.1016/j.acra.2013.09.010. (<B><A HREF=\\"http://www.sciencedirect.com/science/article/pii/S1076633213004182\\">MASS paper</A></B>)\\n<P><BR>\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)"},"subjectImage1":{"type":"attachment","label":"Subject Image (LPS oriented)","help":"Type NIFTi. Providing multiple images will run MASS for each image. Bias correcting the input image may yield better results","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%","min":1,"max":255}}},"optional":{"label":"Options","open":false,"fields":{"noCere":{"type":"select","label":"Indicate whether to use templates with or without cerebellum","choices":{"0":"with cerebellum","1":"without cerebellum"},"required":false},"numTemp":{"type":"integer","label":"Number of templates to be used for registrations. 1 < regs <=15 ","min":2,"max":15,"def":15,"required":false},"regWt":{"type":"float","label":"Regularization Weight for the DRAMMS registration. 0 < g <= 1","min":0,"max":1,"def":0.05,"required":false},"keepInt":{"type":"select","label":"Save intermediate files?","choices":{"0":"Delete all intermediate files","1":"Keep only the important files","2":"Keep all intermediate files"},"required":false}}}},"appKey":"mass"},{"label":"MUSE ROI Labeling","description":"<B><A HREF=\\"https://www.cbica.upenn.edu/sbia/software/MUSE/index.html\\">MUSE Web page</A></B>\\n<P><BR>\\nMUSE is a Multi Atlas ROI Segmentation tool that uses the multi-atlas registration based approach \\nalong with intensity weighting to parcellate the given human brain into a set of 153 regions of anatomical interest.\\n<P><BR>\\n\\n<B><A> Citation</A></B>: Jimit Doshi, Guray Erus, Yangming Ou, Susan M. Resnick, Ruben C. Gur, Raquel E. Gur, Theodore D. Satterthwaite, Susan Furth, Christos Davatzikos, MUSE: MUlti-atlas region Segmentation utilizing Ensembles of registration algorithms and parameters, and locally optimal atlas selection, NeuroImage, Volume 127, 15 February 2016, Pages 186-195, ISSN 1053-8119, http://dx.doi.org/10.1016/j.neuroimage.2015.11.073. (<B><A HREF=\\"http://www.sciencedirect.com/science/article/pii/S1053811915011106\\">MUSE paper</A></B>)\\n<P><BR>\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)"},"subjectImage1":{"type":"attachment","label":"Subject Image (LPS oriented)","help":"Type NIFTi. Providing multiple images will run MUSE for each image. Input image must have LPS orientation, must be bias corrected (N4) and skull-stripped (MASS).","required":true,"validator":"/home/nodeapps/bin/validateimage --type nifti --imagefile %filename%","min":1,"max":255}}},"optional":{"label":"Options","open":false,"fields":{"method":{"type":"select","label":"Registration method(s) to use for registering the templates to the input image","choices":{"1":"DRAMMS","2":"ANTS","3":"DRAMMS+ANTS"},"def":3,"required":false},"keepRanks":{"type":"select","label":"Keep the individual Rank Masks generated for each ROI?","choices":{"0":"NO","1":"YES"},"required":false},"noIC":{"type":"select","label":"Apply Intensity Correction on the probabilities?","choices":{"0":"APPLY","1":"DO NOT APPLY"},"required":false},"noSim":{"type":"select","label":"Apply Similarity Ranking on the probabilities?","choices":{"0":"APPLY","1":"DO NOT APPLY"},"required":false},"noFuzzy":{"type":"select","label":"Apply Fuzzy Segmentation of CSF to the probabilities?","choices":{"0":"APPLY","1":"DO NOT APPLY"},"required":false},"noCere":{"type":"select","label":"Indicate whether to use templates with or without cerebellum","choices":{"0":"with cerebellum","1":"without cerebellum"},"required":false},"maskWML":{"type":"attachment","label":"WML mask (binary) which will be excluded from intensity correction","required":false},"wtCSF":{"type":"float","label":"CSF Weight for MICO segmentation used to improve brain/non-brain segmentation","def":1.2,"required":false},"numTemp":{"type":"integer","label":"Number of templates to be used for registrations. 1 < regs <= 35.","min":2,"max":35,"def":11,"required":false},"regWt":{"type":"float","label":"Regularization Weight for the DRAMMS registration. 0 < g <= 1.","min":0,"max":1,"def":0.1,"required":false},"syn":{"type":"float","label":"GradStep for greedy symmetric norm diffeomorphic model for ANTS registration. 0 < s <= 1.","min":0,"max":1,"def":0.5,"required":false},"keepInt":{"type":"select","label":"Save intermediate files?","choices":{"0":"Delete all intermediate files","1":"Keep only the important files","2":"Keep all intermediate files"},"required":false}}}},"appKey":"muse"},{"label":"Sample IPP Job","description":"<P><BR>\\nThis job demonstrates some of the features of the IPP and runs just long enough to show various job stages. The job takes various input files (of any type) and performs selected operations.\\n<BR><BR><BR>\\n $Revision: 116 $<BR>$LastChangedDate: 2015-10-26 16:19:09 -0500 (Mon, 26 Oct 2015) $\\n","validator":"/bin/true","starter":"/bin/true","fieldGroups":{"required":{"label":"Required Fields","open":true,"fields":{"experimentName":{"type":"string","label":"Experiment Name","required":true},"experimentDescription":{"type":"string","label":"Description (optional)"},"groundTruth":{"type":"attachment","label":"Ground truth","help":"A single file, of any type, to be compared in various ways to each of the data files","required":true,"validator":"/bin/true","min":1,"max":1},"inputs":{"type":"attachment","label":"Data files","help":"One or more of any type of file","required":true,"validator":"/bin/true","min":1,"max":255},"operation1":{"type":"select","label":"Checksum method","help":"Select the method used to produce checksums","choices":{"0":"sha512sum","1":"md5sum"},"required":true}}},"optional":{"label":"Options","open":true,"fields":{"operation2":{"type":"select","label":"Sum of bytes","help":"Produce a sum of the ASCII values of the printable representation of all characters in each input file. This is a completely useless value.","choices":{"0":"No","1":"Yes"},"required":false},"count":{"type":"integer","label":"Number of iterations","help":"Produce a checksum of this many instances of the file, concatenated together. Default=3","def":3,"min":0,"max":20,"required":false},"random":{"type":"select","label":"Apply a random factor","help":"If chosen, the program will compute a random value and apply it to various calculations in the results.","choices":{"0":"Yes","1":"No"},"required":false,"def":0},"Revision":{"label":"$Revision: 116 $","type":"string","required":false,"def":""},"LastChanged":{"label":"$LastChangedDate: 2015-10-26 16:19:09 -0500 (Mon, 26 Oct 2015) $","type":"string","required":false,"def":""}}}},"appKey":"sample_job"},{"label":"xcpEngine","starter":"/bin/true","validator":"/bin/true","description":"<B><FONT COLOR=\'#33d6ff\'><A HREF=\\"https://pipedocs.github.io/index.html\\">XCP Engine documentation and development hub</A></FONT></B><BR>\\n<P><BR>\\nxcpEngine - A multimodal neuroimaging pipeline<BR>\\n\\nxcpEngine - xcpEngine v0.6.0 (ACCELERATOR) is the most recent iteration of the BBL\'s neuroimage processing system. This system provides a configurable, modular, agnostic, and multimodal platform for neuroimage processing and quality assessment. It implements a number of high-performance denoising approaches and computes regional and voxelwise values of interest for each modality. The system provides a general-purpose image processing interface, as well as a standard toolkit for benchmarking pipeline performance. All pipelines from <FONT COLOR=\'#33d6ff\'><A HREF=\\"https://www.ncbi.nlm.nih.gov/pubmed/28302591\\">our 2017 benchmarking paper</A></FONT> are implementable, as are the pipelines evaluated in <FONT COLOR=\'#33d6ff\'><A HREF=\\"https://www.biorxiv.org/content/early/2017/11/05/156380\\">the recent work of Parkes and colleagues</A></FONT>. As of v0.6.0, functional and anatomical modalities are supported, with perfusion and diffusion under development.\\n<P><BR>\\n","fieldGroups":{"required":{"fields":{"experimentName":{"type":"string","label":"Provide a name for your experiment","required":true},"experimentDescription":{"type":"string","label":"Description of your experiment (optional)","required":false},"designFile":{"help":"Design file for the pipeline. Pipelines are configured using parameters in a user-provided design file, which can be readily constructed from a template using <FONT COLOR=\'#33d6ff\'><A HREF=\'https://github.com/PennBBL/xcpConfig\'>the lightweight xcpConfig code</A></FONT>. Template designs for anatomical and functional connectivity processing are currently available. More extensive documentation, including examples, can be found at <FONT COLOR=\'#33d6ff\'><A HREF=\'https://pipedocs.github.io/config/design.html\'>pipedocs</A></FONT>.","label":"Design File","max":1,"min":1,"required":true,"type":"attachment"},"cohortFile":{"help":"Cohort file for the pipeline. The cohort file defines the experimental sample, including subject identifiers and input names for each subject. For details and examples, visit <FONT COLOR=\'#33d6ff\'><A HREF=\'https://pipedocs.github.io/config/cohort.html\'>the relevant pipedocs page</A></FONT>. For processing on IPP, input paths should be stripped of any leading directories; they should include the base name of the file only.","label":"Cohort File","max":1,"min":1,"required":true,"type":"attachment"},"cohortInputs":{"min":1,"label":"Input images and files for processing using xcpEngine","help":"Please select all input images and files listed in the cohort file. The expected file type is \'.nii.gz\' for single images and \'.tar.gz\' for processing directories (such as the struc module output or the ANTs Cortical Thickness directory), which should be archived and compressed before processing.","required":true,"type":"attachment"}},"label":"Required Fields","open":true},"optional":{"label":"Options","open":false,"fields":{"verboseLevel":{"label":"Diagnostics (0: quiet, 1: verbose, 2: more verbose)","help":"If \'0\' is selected, logs will include only descriptive messages. If \'1\' is selected, any image processing commands run by the pipeline will be printed explicitly in the log, facilitating error diagnosis. If \'2\' is selected, image processing commands run by the pipeline and any child commands that they call will be printed explicitly in the log.","type":"select","choices":{"0":"0","1":"1","2":"2"},"def":1}}}},"appKey":"xcpEngine"}]')},18:function(e){e.exports=JSON.parse('[{"id":"institution","name":"Academic affiliation or company name","type":"text","required":true,"pattern":".*"},{"id":"fname","name":"First name","type":"text","required":true,"pattern":".*"},{"id":"lname","name":"Last name","type":"text","required":true,"pattern":".*"},{"id":"intention","name":"Intended use","type":"textarea","required":true,"pattern":".*"},{"id":"referral","name":"Where did you hear about this portal?","type":"textarea","required":true,"pattern":".*"},{"id":"nih","name":"Is your use of the CBICA IPP related to an NIH-supported project?","type":"textarea","required":true,"pattern":".*"}]')},23:function(e,t,i){},42:function(e,t,i){},44:function(e,t,i){"use strict";i.r(t);var a=i(1),r=i.n(a),n=i(16),s=i.n(n),l=(i(23),i(6)),o=i(3),d=i(4),u=i.n(d),p=i(5),c=i(17),m=i(18),h=(i(42),i(0)),b="https://cbica1.iaas.upenn.edu:8080";var g=function(){var e,t=function(e){e.preventDefault(),u()({url:b+"/experiments/new",method:"POST",headers:{"Content-Type":"multipart/form-data"},data:new FormData(e.target)}).then((function(e){e.data?(V(),P("experiments")):(y(""),s(!1),localStorage.removeItem("token"))})).catch((function(e){return console.error(e)}))},i=Object(a.useState)(null!==localStorage.getItem("token")),r=Object(o.a)(i,2),n=r[0],s=r[1],d=Object(a.useState)(localStorage.getItem("token")||(null!==(e=new URLSearchParams(window.location.search).get("token"))&&void 0!==e?e:"")),g=Object(o.a)(d,2),f=g[0],y=g[1],v=Object(a.useState)(!1),T=Object(o.a)(v,2),x=T[0],w=T[1],S=Object(a.useState)("apps"),I=Object(o.a)(S,2),j=I[0],P=I[1],q=Object(a.useState)(""),N=Object(o.a)(q,2),R=N[0],B=N[1],D=Object(a.useState)([]),k=Object(o.a)(D,2),O=k[0],C=k[1],A=Object(a.useState)(""),F=Object(o.a)(A,2),M=F[0],z=F[1],_=Object(a.useState)({groups:[]}),E=Object(o.a)(_,2),L=E[0],G=E[1],V=function(){f&&u.a.get("".concat(b,"/experiments"),{params:{token:f}}).then((function(e){e.data.hasOwnProperty("experiments")?C(e.data.experiments):(y(""),s(!1),localStorage.removeItem("token"))})).catch((function(e){console.error(e)}))};return Object(a.useEffect)(V,[f]),Object(a.useEffect)((function(){f&&u.a.get("".concat(b,"/users/groups"),{params:{token:f}}).then((function(e){e.data.hasOwnProperty("groups")?G({groups:e.data.groups}):(y(""),s(!1),localStorage.removeItem("token"))})).catch((function(e){console.error(e)}))}),[f]),n?Object(h.jsxs)("div",{className:"md:flex flex-col md:flex-row md:min-h-screen w-full bg-base-200 overflow-y-auto",children:[Object(h.jsx)("div",{className:"flex flex-col w-auto py-4 px-2",children:Object(h.jsx)("div",{className:"artboard artboard-demo",children:Object(h.jsxs)("ul",{className:"menu py-4 shadow-lg bg-base-100 rounded-box w-full overflow-visible",children:[Object(h.jsx)("li",{className:"menu-title",children:Object(h.jsx)("span",{children:"Image Processing Portal Apps"})}),Object.keys(p).map((function(e,t){return!p[e].hasOwnProperty("groups")||L.hasOwnProperty("groups")&&L.groups.some((function(t){return p[e].groups.includes(t)}))?Object(h.jsxs)("li",{className:"hover-bordered dropdown dropdown-right dropdown-hover",children:[Object(h.jsxs)("a",{href:"#",children:[Object(h.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",fill:"none",viewBox:"0 0 24 24",className:"inline-block w-5 h-5 mr-2 stroke-current",children:Object(h.jsx)("path",{"stroke-linecap":"round","stroke-linejoin":"round","stroke-width":"2",d:"M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z"})}),p[e].label]}),Object(h.jsx)("ol",{className:"shadow-lg menu dropdown-content bg-base-100 w-full pl-0",children:Object(h.jsx)("li",{children:p[e].apps.map((function(e){return Object(h.jsx)("a",{href:"#",onClick:function(){B(e)},className:"block px-4 py-2 mt-2 text-sm font-semibold bg-transparent rounded dark-mode:bg-transparent dark-mode:hover:bg-gray-600 dark-mode:focus:bg-gray-600 dark-mode:focus:text-white dark-mode:hover:text-white dark-mode:text-gray-200 md:mt-0 hover:text-gray-900 focus:text-gray-900 hover:bg-gray-200 focus:bg-gray-200 focus:outline-none focus:shadow-outline",children:e})}))})})]}):Object(h.jsx)("div",{})}))]})})}),Object(h.jsxs)("div",{className:"flex flex-col w-full py-4 px-2",children:[Object(h.jsxs)("div",{className:"navbar mb-2 shadow-lg bg-base-100 rounded-box",children:[Object(h.jsx)("div",{className:"flex-1 px-2 mx-2",children:Object(h.jsx)("span",{className:"text-lg font-bold",children:"Image Processing Portal"})}),Object(h.jsx)("div",{className:"flex-none hidden px-2 mx-2 lg:flex",children:Object(h.jsxs)("div",{className:"flex items-stretch",children:[Object(h.jsxs)("a",{onClick:function(){return P("apps")},className:"btn btn-ghost btn-sm rounded-btn",children:[Object(h.jsx)("svg",{className:"inline-block w-5 mr-2 stroke-current",width:"18",height:"18",viewBox:"0 0 18 18",fill:"none",xmlns:"http://www.w3.org/2000/svg",children:Object(h.jsx)("path",{strokeWidth:.1,d:"M7.33335 9.83342H1.50002C1.27901 9.83342 1.06704 9.92121 0.910765 10.0775C0.754484 10.2338 0.666687 10.4457 0.666687 10.6667V16.5001C0.666687 16.7211 0.754484 16.9331 0.910765 17.0893C1.06704 17.2456 1.27901 17.3334 1.50002 17.3334H7.33335C7.55437 17.3334 7.76633 17.2456 7.92261 17.0893C8.07889 16.9331 8.16669 16.7211 8.16669 16.5001V10.6667C8.16669 10.4457 8.07889 10.2338 7.92261 10.0775C7.76633 9.92121 7.55437 9.83342 7.33335 9.83342ZM6.50002 15.6667H2.33335V11.5001H6.50002V15.6667ZM16.5 0.666748H10.6667C10.4457 0.666748 10.2337 0.754545 10.0774 0.910826C9.92115 1.06711 9.83335 1.27907 9.83335 1.50008V7.33342C9.83335 7.55443 9.92115 7.76639 10.0774 7.92267C10.2337 8.07895 10.4457 8.16675 10.6667 8.16675H16.5C16.721 8.16675 16.933 8.07895 17.0893 7.92267C17.2456 7.76639 17.3334 7.55443 17.3334 7.33342V1.50008C17.3334 1.27907 17.2456 1.06711 17.0893 0.910826C16.933 0.754545 16.721 0.666748 16.5 0.666748ZM15.6667 6.50008H11.5V2.33341H15.6667V6.50008ZM16.5 9.83342H10.6667C10.4457 9.83342 10.2337 9.92121 10.0774 10.0775C9.92115 10.2338 9.83335 10.4457 9.83335 10.6667V16.5001C9.83335 16.7211 9.92115 16.9331 10.0774 17.0893C10.2337 17.2456 10.4457 17.3334 10.6667 17.3334H16.5C16.721 17.3334 16.933 17.2456 17.0893 17.0893C17.2456 16.9331 17.3334 16.7211 17.3334 16.5001V10.6667C17.3334 10.4457 17.2456 10.2338 17.0893 10.0775C16.933 9.92121 16.721 9.83342 16.5 9.83342ZM15.6667 15.6667H11.5V11.5001H15.6667V15.6667ZM7.33335 0.666748H1.50002C1.27901 0.666748 1.06704 0.754545 0.910765 0.910826C0.754484 1.06711 0.666687 1.27907 0.666687 1.50008V7.33342C0.666687 7.55443 0.754484 7.76639 0.910765 7.92267C1.06704 8.07895 1.27901 8.16675 1.50002 8.16675H7.33335C7.55437 8.16675 7.76633 8.07895 7.92261 7.92267C8.07889 7.76639 8.16669 7.55443 8.16669 7.33342V1.50008C8.16669 1.27907 8.07889 1.06711 7.92261 0.910826C7.76633 0.754545 7.55437 0.666748 7.33335 0.666748ZM6.50002 6.50008H2.33335V2.33341H6.50002V6.50008Z",fill:"currentColor"})}),"Apps"]}),Object(h.jsxs)("div",{className:"indicator",children:[Object(h.jsx)("div",{className:"indicator-item badge badge-secondary"+(0===O.length?" hidden":""),children:O.length}),Object(h.jsxs)("a",{onClick:function(){return P("experiments")},className:"btn btn-ghost btn-sm rounded-btn",children:[Object(h.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",fill:"none",viewBox:"0 0 24 24",className:"inline-block w-5 mr-2 stroke-current",children:Object(h.jsx)("path",{"stroke-linecap":"round","stroke-linejoin":"round","stroke-width":"2",d:"M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z"})}),"Experiments"]})]})]})}),Object(h.jsx)("div",{className:"flex-none",children:Object(h.jsxs)("div",{className:"dropdown dropdown-end",children:[Object(h.jsx)("button",{className:"btn btn-ghost btn-square",children:Object(h.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",fill:"none",viewBox:"0 0 24 24",className:"inline-block w-6 h-6 stroke-current",children:Object(h.jsx)("path",{"stroke-linecap":"round","stroke-linejoin":"round","stroke-width":"2",d:"M4 6h16M4 12h16M4 18h16"})})}),Object(h.jsxs)("ul",{className:"shadow menu dropdown-content bg-base-100 rounded-box w-52",children:[Object(h.jsx)("li",{className:"p-5",children:Object(h.jsx)("form",{action:"#",children:Object(h.jsx)("div",{className:"form-control",children:Object(h.jsxs)("label",{className:"cursor-pointer label",children:[Object(h.jsx)("span",{className:"label-text",children:"Email notifications"}),Object(h.jsx)("input",{type:"checkbox",className:"checkbox checkbox-primary"})]})})})}),Object(h.jsx)("li",{className:"p-5",children:Object(h.jsx)("form",{action:"#",children:Object(h.jsx)("div",{className:"form-control",children:Object(h.jsxs)("label",{className:"cursor-pointer label",children:[Object(h.jsx)("span",{className:"label-text",children:"Slack notifications"}),Object(h.jsx)("input",{type:"checkbox",className:"checkbox checkbox-primary"})]})})})}),Object(h.jsx)("li",{children:Object(h.jsx)("a",{onClick:function(e){e.preventDefault(),s(!1),y(""),localStorage.removeItem("token")},href:"/",role:"menuitem",children:"Sign out"})})]})]})})]}),"apps"===j&&""===R?Object(h.jsx)("p",{className:"p-10 mt-4",children:"Please select an app"}):"","experiments"===j&&0===O.length?Object(h.jsx)("p",{className:"p-10 mt-4",children:"You have no experiments"}):"",c.map((function(e,i){var a;return Object(h.jsxs)("div",{className:e.appKey===R&&"apps"===j?"p-10 mt-4":"p-10 mt-4 hidden",children:[Object(h.jsx)("h2",{className:"text-3xl font-semibold",children:e.label}),Object(h.jsxs)("form",{onSubmit:t,method:"POST",action:"#",children:[Object(h.jsx)("input",{name:"token",type:"hidden",value:f}),Object(h.jsx)("input",{readOnly:!0,name:"app",type:"hidden",value:e.appKey}),Object(h.jsxs)("div",{className:"grid grid-cols-1 lg:grid-cols-2 lg:gap-4",children:[Object.keys(Object(l.a)(Object(l.a)({},e.fieldGroups.required.fields),null===(a=e.fieldGroups.optional)||void 0===a?void 0:a.fields)).map((function(t,i){var a,r,n,s,o,d=Object(l.a)(Object(l.a)({},e.fieldGroups.required.fields),null===(a=e.fieldGroups.optional)||void 0===a?void 0:a.fields);switch(d[t].type){case"string":return Object(h.jsxs)("div",{className:"form-control",children:[Object(h.jsx)("label",{className:"label",children:Object(h.jsx)("span",{className:"label-text",children:null===(r=d[t])||void 0===r?void 0:r.label})}),Object(h.jsx)("input",{type:"text",name:t,className:"input input-bordered input-primary",placeholder:""})]});case"integer":case"float":return Object(h.jsxs)("div",{className:"form-control",children:[Object(h.jsx)("label",{className:"label",children:Object(h.jsx)("span",{className:"label-text",children:null===(n=d[t])||void 0===n?void 0:n.label})}),Object(h.jsx)("input",{type:"number",name:t,className:"input input-bordered input-primary",placeholder:""})]});case"select":return Object(h.jsxs)("div",{className:"form-control",children:[Object(h.jsx)("label",{className:"label",children:Object(h.jsx)("span",{className:"label-text",children:null===(s=d[t])||void 0===s?void 0:s.label})}),Object(h.jsx)("select",{name:t,className:"select select-bordered select-primary w-full",children:Object.keys(d[t]?d[t].choices:{}).map((function(e){var i;return Object(h.jsx)("option",{value:e,children:null===(i=d[t])||void 0===i?void 0:i.choices[e]})}))})]});case"attachment":return Object(h.jsxs)("label",{className:"block lg:-mt-2 lg:-mb-2",children:[Object(h.jsx)("span",{children:null===(o=d[t])||void 0===o?void 0:o.label}),Object(h.jsx)("input",{type:"file",name:t,multiple:!0,className:"mt-1 block w-full"})]});default:return Object(h.jsxs)("div",{children:["There seems to be a misconfigured field:",Object(h.jsx)("br",{}),Object(h.jsx)("pre",{children:JSON.stringify(d[t],null,2)})]})}})),Object(h.jsxs)("div",{className:"form-control",children:[Object(h.jsx)("label",{className:"label",children:Object(h.jsx)("span",{className:"label-text",children:"Execute host"})}),Object(h.jsxs)("select",{name:"host",className:"select select-bordered select-primary w-full",children:[Object(h.jsx)("option",{value:"cubic",children:"CUBIC"}),Object(h.jsx)("option",{value:"localhost",children:"Localhost"}),Object(h.jsx)("option",{value:"cbica1",children:"IPP server"})]})]})]}),Object(h.jsx)("label",{className:"block mt-3",children:Object(h.jsx)("button",{className:"btn btn-primary",type:"submit",children:"Submit"})})]})]})})),Object(h.jsx)("div",{className:"experiments"===j&&O.length>0?"pl-3 pr-10":"pl-3 pr-10 hidden",children:Object(h.jsx)("div",{className:"overflow-x-auto",children:Object(h.jsxs)("table",{className:"table w-full",children:[Object(h.jsx)("thead",{children:Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{}),Object(h.jsx)("th",{children:"Name"}),Object(h.jsx)("th",{children:"Description"}),Object(h.jsx)("th",{children:"App"}),Object(h.jsx)("th",{children:"Created"}),Object(h.jsx)("th",{children:"Outputs"}),Object(h.jsx)("th",{children:"Params"}),Object(h.jsx)("th",{children:"Status"})]})}),Object(h.jsx)("tbody",{children:O.map((function(e,t){return Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:t+1}),Object(h.jsx)("td",{children:e.experimentName}),Object(h.jsx)("td",{children:e.experimentDescription}),Object(h.jsx)("td",{children:e.app}),Object(h.jsx)("td",{children:e.created}),Object(h.jsx)("td",{children:Array.from(e.outputs).map((function(t){return Object(h.jsx)("a",{href:b+"/experiments/"+e.id+"/file?"+new URLSearchParams({token:f,path:t}).toString(),target:"_blank",children:t})}))}),Object(h.jsx)("td",{children:Object.keys(e.params).map((function(t,i){return Array.from(e.inputs).includes(e.params[t])?Object(h.jsx)("ul",{children:Object(h.jsxs)("li",{children:[t,": ",Object(h.jsx)("a",{href:b+"/experiments/"+e.id+"/file?"+new URLSearchParams({token:f,path:e.params[t]}).toString(),target:"_blank",children:e.params[t]})]})}):Object(h.jsx)("ul",{children:Object(h.jsxs)("li",{children:[t,": ",e.params[t]]})})}))}),Object(h.jsx)("td",{style:{textTransform:"capitalize"},children:e.status})]})}))})]})})})]})]}):Object(h.jsxs)("div",{className:"hero min-h-screen bg-base-200",children:[Object(h.jsx)("div",{id:"tos",className:"modal w-full",children:Object(h.jsxs)("div",{className:"modal-box max-w-none w-3/4 overflow-y-scroll max-h-screen",children:[Object(h.jsx)("h1",{className:"font-extrabold text-4xl text-center",children:"Terms of Service"}),Object(h.jsx)("p",{className:"text-center mb-2",children:"2015-08-12"}),Object(h.jsx)("h2",{className:"text-2xl font-bold mb-1 mt-2",children:"Acceptable Data"}),Object(h.jsx)("p",{children:"Do not upload files to the IPP containing Protected Health Information, as defined the federal Health Insurance Portability and Accountability Act (\u201cHIPAA\u201d), or any data that identifies research subjects individually (together, \u201cPersonally Identifiable Information\u201d or \u201cPII\u201d)."}),Object(h.jsx)("h2",{className:"text-2xl font-bold mb-1 mt-2",children:"Data Use and Retention"}),Object(h.jsxs)("ul",{className:"list-disc list-inside",children:[Object(h.jsx)("li",{children:"UPHS will not be responsible for safeguarding any PII data that may be accidentally uploaded to the IPP."}),Object(h.jsx)("li",{children:"UPHS will not make any use of images or data uploaded to the IPP, except as necessary to provide the requested image processing services."}),Object(h.jsx)("li",{children:"UPHS will not store data beyond the term needed to perform the image processing as requested by the submitter."}),Object(h.jsx)("li",{children:"UPHS will not store results of processing beyond a short period deemed appropriate by UPHS in its sole discretion to allow such results to be downloaded."})]}),Object(h.jsx)("h2",{className:"text-2xl font-bold mb-1 mt-2",children:"Terms of Use"}),Object(h.jsxs)("ul",{className:"list-disc list-inside",children:[Object(h.jsx)("li",{children:"The party providing data to CBICA for analysis is solely responsible for complying with any restrictions imposed by the original supplier of the data and any applicable laws and regulations, including but not limited to those governing data collection, use, and transfer."}),Object(h.jsx)("li",{children:'Parties submitting data to CBICA for processing agree to use all results generated by the IPP solely for non-commercial use. The term "non-commercial," as applied to use of the CBICA Image Processing Portal, means academic or other scholarly research which (a) is not undertaken for profit, or (b) is not intended to produce work, services, or data for commercial use, or (c) is neither conducted, nor funded, by a person or an entity engaged in a commercial process of medical image analysis. Academic sponsored research is not a commercial use under the terms of this Agreement.'}),Object(h.jsx)("li",{children:"The software has been designed for research purposes only and has not been reviewed or approved by the Food and Drug Administration or by any other agency. It is not intended or recommended for clinical applications."}),Object(h.jsx)("li",{children:"UPHS reserves the right to cancel IPP accounts without prior notice. All data associated with cancelled accounts will be removed."}),Object(h.jsx)("li",{children:"Data processing through the IPP is provided on a best effort basis, with no guarantee of timely delivery."}),Object(h.jsx)("li",{children:'Users of the IPP agree to conspicuously acknowledge "CBICA" and the specific analysis method[s] employed through the IPP in any publications resulting from their use of the IPP.'})]}),Object(h.jsx)("p",{className:"mt-2",children:"Revision 1.2, Wed Aug  12 13:04:00 EDT 2015"}),Object(h.jsx)("div",{className:"modal-action",children:Object(h.jsx)("a",{href:window.location.href.split("#")[0]+"#",className:"btn btn-primary",children:"Close"})})]})}),Object(h.jsxs)("div",{className:"flex-col justify-center hero-content lg:flex-row",children:[Object(h.jsxs)("div",{className:"text-center lg:text-left",children:[Object(h.jsx)("h1",{className:"mb-5 text-5xl font-bold",children:"Welcome!"}),Object(h.jsx)("p",{className:"mb-5",children:"The CBICA Image Processing Portal is available for authorized users to access the Center for Biomedical Image Computing and Analytics computing cluster and imaging analytics pipelines on their own, free of charge, without the need to download and install any of our software. In this first phase of the project, we have provided a limited set of well streamlined pipelines covering methods of broad interest. We welcome your suggestions to adapt these pipelines to suit your specific needs."}),Object(h.jsxs)("p",{className:"mb-5",children:["Many CBICA image processing algorithms and pre-processing tools are available for stand-alone use through the Cancer Imaging Phenomics Toolkit (CaPTk) software package. This open-source software is designed for general-purpose quantitative medical image analysis and specialized diagnostics (such as survival and recurrence prediction of glioblastoma) and is now available for download at: ",Object(h.jsx)("a",{href:"https://www.cbica.upenn.edu/captk",target:"_blank",className:"link link-accent",children:"https://www.cbica.upenn.edu/captk"})]}),Object(h.jsx)("p",{className:"mb-5",children:"If you use our pipelines in your own publication we ask that you cite our respective publications. Moreover, we ask that you cite the portal as follows:"}),Object(h.jsx)("p",{className:"mb-5",children:Object(h.jsx)("blockquote",{className:"border-l-4 pl-3",children:"CBICA Image Processing Portal; https://ipp.cbica.upenn.edu/.  A web accessible platform for imaging analytics; Center for Biomedical Image Computing and Analytics, University of Pennsylvania."})}),Object(h.jsxs)("div",{className:"w-full carousel rounded-box",children:[Object(h.jsx)("div",{className:"carousel-item w-1/2",children:Object(h.jsx)("img",{src:"https://ipp.cbica.upenn.edu/uploads/files/837739763739754523-img04.full.jpg",className:"w-full"})}),Object(h.jsx)("div",{className:"carousel-item w-1/2",children:Object(h.jsx)("img",{src:"https://ipp.cbica.upenn.edu/uploads/files/72100511629801360-img05.full.jpg",className:"w-full"})}),Object(h.jsx)("div",{className:"carousel-item w-1/2",children:Object(h.jsx)("img",{src:"https://ipp.cbica.upenn.edu/uploads/files/549317001114620719-img06.full.jpg",className:"w-full"})}),Object(h.jsx)("div",{className:"carousel-item w-1/2",children:Object(h.jsx)("img",{src:"https://ipp.cbica.upenn.edu/uploads/files/604887918702357499-img07.full.jpg",className:"w-full"})})]}),Object(h.jsxs)("p",{className:"text-sm mt-2",children:["Center for Biomedical Image Computing and Analytics, University of Pennsylvania \xb7 ",Object(h.jsx)("a",{href:"mailto:ipp-support@cbica.upenn.edu",className:"link link-primary",children:"Contact"})," \xb7 ",Object(h.jsx)("a",{href:"http://www.cbica.upenn.edu/",target:"_blank",rel:"noreferrer",className:"link link-primary",children:"About"})]})]}),Object(h.jsx)("div",{className:"card flex-shrink-0 w-full max-w-sm shadow-2xl bg-base-100",children:Object(h.jsxs)("div",{className:"card-body",children:[Object(h.jsxs)("div",{className:"bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative "+(""===M?"hidden":""),role:"alert",children:[Object(h.jsx)("strong",{className:"font-bold",children:"Heads up!"}),Object(h.jsx)("span",{style:{textTransform:"capitalize"},className:"block sm:inline ml-2",children:M}),Object(h.jsx)("button",{type:"button",onClick:function(){return z("")},children:Object(h.jsx)("span",{className:"absolute top-0 bottom-0 right-0 px-4 py-3",children:Object(h.jsxs)("svg",{className:"fill-current h-6 w-6 text-red-500",role:"button",xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 20 20",children:[Object(h.jsx)("title",{children:"Close"}),Object(h.jsx)("path",{d:"M14.348 14.849a1.2 1.2 0 0 1-1.697 0L10 11.819l-2.651 3.029a1.2 1.2 0 1 1-1.697-1.697l2.758-3.15-2.759-3.152a1.2 1.2 0 1 1 1.697-1.697L10 8.183l2.651-3.031a1.2 1.2 0 1 1 1.697 1.697l-2.758 3.152 2.758 3.15a1.2 1.2 0 0 1 0 1.698z"})]})})})]}),Object(h.jsx)("p",{className:"mt-2 text-center text-sm",children:Object(h.jsxs)("div",{className:"divider text-sm m-0 mb-2 uppercase",children:[Object(h.jsxs)("button",{onClick:function(){return w(!x)},className:"btn btn-secondary btn-xs mr-2",children:[" ",x?"Sign in":"Create an account"]})," or"]})}),Object(h.jsx)("h2",{className:"card-title text-2xl text-center mb-1",children:x?"Create your account":"Sign in to your account"}),Object(h.jsxs)("form",{className:"mt-2",action:"#",method:"POST",onSubmit:x?function(e){e.preventDefault(),e.target.querySelector('[name="password"]').value!==e.target.querySelector('[name="confirm-password"]').value&&e.target.querySelector('[name="confirm-password"]').setCustomValidity("Passwords don't match"),e.target.reportValidity(),e.target.checkValidity()&&u()({url:b+"/users/new",method:"POST",headers:{"Content-Type":"multipart/form-data"},data:new FormData(e.target)}).then((function(e){e.data?(alert("Account created, please wait for approval"),w(!1)):(console.error(e.data.error),z(e.data.error))})).catch((function(e){z(e.message),console.error(e)}))}:function(e){e.preventDefault(),u()({url:b+"/users/auth",method:"POST",headers:{"Content-Type":"multipart/form-data"},data:new FormData(e.target)}).then((function(e){e.data.token?(localStorage.setItem("token",e.data.token),y(e.data.token),s(!0)):z(e.data.error)})).catch((function(e){return console.error(e)}))},children:[Object(h.jsx)("input",{type:"hidden",name:"remember",defaultValue:"true"}),Object(h.jsxs)("div",{className:"form-control",children:[Object(h.jsx)("label",{htmlFor:"email-address",className:"sr-only",children:"Email address"}),Object(h.jsx)("input",{id:"email-address",name:"email",type:"email",autoComplete:"email",required:!0,onInvalid:function(e){return e.target.setCustomValidity("Please enter a valid email")},className:"input input-bordered",placeholder:"Email address"})]}),Object(h.jsxs)("div",{className:"mt-2 form-control",children:[Object(h.jsx)("label",{htmlFor:"password",className:"sr-only",children:"Password"}),Object(h.jsx)("input",{id:"password",name:"password",type:"password",autoComplete:"current-password",required:!0,minLength:6,className:"input input-bordered",placeholder:"Password"})]}),x?Object(h.jsxs)("div",{className:"mt-2 form-control",children:[Object(h.jsx)("label",{htmlFor:"confirm-password",className:"sr-only",children:"Confirm password"}),Object(h.jsx)("input",{name:"confirm-password",id:"confirm-password",type:"password",required:!0,minLength:6,className:"input input-bordered",placeholder:"Confirm password"})]}):"",x?m.map((function(e){switch(e.type){case"textarea":return Object(h.jsxs)("div",{className:"mt-2 form-control",children:[Object(h.jsx)("label",{htmlFor:e.id,className:"sr-only",children:e.name}),Object(h.jsx)("textarea",{name:"setting-"+e.id,id:e.id,required:e.required,className:"textarea textarea-bordered",placeholder:e.name})]});default:return Object(h.jsxs)("div",{className:"mt-2 form-control",children:[Object(h.jsx)("label",{htmlFor:e.id,className:"sr-only",children:e.name}),Object(h.jsx)("input",{name:"setting-"+e.id,id:e.id,type:e.type,required:e.required,pattern:e.pattern,className:"input input-bordered",placeholder:e.name})]})}})):"",x?Object(h.jsx)("div",{className:"mt-2 form-control",children:Object(h.jsxs)("label",{className:"cursor-pointer label",children:[Object(h.jsxs)("span",{className:"label-text",children:["Agree to ",Object(h.jsx)("a",{href:"#tos",className:"link link-primary",children:"terms of service"})]}),Object(h.jsx)("input",{id:"tos-check",type:"checkbox",required:!0,className:"checkbox checkbox-primary"})]})}):"",Object(h.jsx)("div",{className:"form-control mt-6",children:Object(h.jsxs)("button",{className:"group relative flex justify-center btn btn-primary btn-block mt-2",children:[Object(h.jsx)("span",{className:"absolute left-0 inset-y-0 flex items-center pl-3",children:Object(h.jsx)("svg",{className:"h-5 w-5 text-gray-900 opacity-20 mix-blend-multiply",xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 20 20",fill:"currentColor","aria-hidden":"true",children:Object(h.jsx)("path",{fillRule:"evenodd",d:"M5 9V7a5 5 0 0110 0v2a2 2 0 012 2v5a2 2 0 01-2 2H5a2 2 0 01-2-2v-5a2 2 0 012-2zm8-2v2H7V7a3 3 0 016 0z",clipRule:"evenodd"})})}),"Sign ",x?"up":"in"]})})]})]})})]})]})},f=function(e){e&&e instanceof Function&&i.e(3).then(i.bind(null,45)).then((function(t){var i=t.getCLS,a=t.getFID,r=t.getFCP,n=t.getLCP,s=t.getTTFB;i(e),a(e),r(e),n(e),s(e)}))};s.a.render(Object(h.jsx)(r.a.StrictMode,{children:Object(h.jsx)(g,{})}),document.getElementById("root")),f()},5:function(e){e.exports=JSON.parse('{"development":{"apps":["BraTS19eval_testingPhase","BraTS19eval_testingPhase_Survival","BraTS19eval_testingPhase_Uncertainty","BraTS20eval_testingPhase","BraTS20eval_testingPhase_Survival","BraTS20eval_testingPhase_Uncertainty","CaPTkBiasCorrection","CaPTkBraTSPreprocessingPipeline","CaPTkDiffusionDerivatives","CaPTkHistogramMatching","CaPTkImageRegistration","CaPTkPerfusionDerivatives","CaPTkSusanDenoising","CaPTkZScoreNormalization","Compare","DBN_def","DeepMedic_brainTumor","DeepMedic_modalityagnostic_skullstripping","DeepMedic_skullStripping","FeatureExtractionBranch","FeTS21eval_testingPhase","GLISTRboost","GraSP","mass","muse","StructuralPipeline"],"description":"Experiments in development, only visible to CBICA Developers group","groups":["CBICA Developers"],"label":"Development and Testing"},"segmentation":{"apps":["WMLS","GLISTR","brainmage_v1"],"description":"Various segmentation methods","label":"Segmentation"},"brats2020":{"apps":["BraTS20_registration","BraTS20eval_trainingPhase_Survival","BraTS20eval_trainingPhase","BraTS20eval_trainingPhase_Uncertainty","BraTS20eval_validationPhase_Uncertainty","BraTS20eval_validationPhase_Survival","BraTS20eval_validationPhase"],"description":"MICCAI BraTS 2020 Analysis and Submission","label":"MICCAI BraTS 2020"},"pipelines":{"apps":["xcpEngine"],"description":"Various pipelines methods","label":"Processing pipelines"},"brats2018":{"apps":["BraTS18_registration","BraTS18eval_trainingPhase","BraTS18eval_trainingPhase_Survival","BraTS18eval_validationPhase","BraTS18eval_validationPhase_Survival"],"description":"MICCAI BraTS 2018 Analysis and Submission","label":"MICCAI BraTS 2018"},"brats2019":{"apps":["BraTS19_registration","BraTS19eval_trainingPhase","BraTS19eval_trainingPhase_Survival","BraTS19eval_trainingPhase_Uncertainty","BraTS19eval_validationPhase","BraTS19eval_validationPhase_Survival","BraTS19eval_validationPhase_Uncertainty"],"description":"MICCAI BraTS 2019 Analysis and Submission","label":"MICCAI BraTS 2019"},"CaPTk":{"apps":["LIBRA","GLISTR","brainmage_v1","MultiSubjectFeatureExtractionBranch"],"description":"Many CBICA image processing algorithms and pre-processing tools are available for stand-alone use through the Cancer Imaging Phenomics Toolkit (CaPTk) software package. This open-source software is designed for general-purpose quantitative medical image analysis and specialized diagnostics (such as survival and recurrence prediction of glioblastoma) and is now available for download at: https://www.med.upenn.edu/cbica/captk/","label":"Cancer Imaging Phenomics Toolkit"},"analysis":{"apps":["ODVBA","LIBRA","SCPLearn","MultiSiteSCZClassifier"],"description":"Various analysis methods","label":"Analysis"},"registration":{"apps":["DRAMMS-coregistration","DRAMMS-Ravens"],"description":"Various registration methods","label":"Registration"},"fets2020":{"apps":["FeTS21_registration","FeTS21eval_trainingPhase","FeTS21eval_validationPhase"],"description":"MICCAI FeTS 2021 (Challenge on Federated Learning)","label":"MICCAI FeTS 2021 (Challenge on Federated Learning)"}}')}},[[44,1,2]]]);
//# sourceMappingURL=main.ab4d842a.chunk.js.map